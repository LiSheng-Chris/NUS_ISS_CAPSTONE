% Template; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx}

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

% Title.
% ------
\title{Graduate Certificate Intelligent Sensing Systems Practice Module Report Template}
%
% Single address.
% ---------------
\name{First1 Last1,  First2 Last2}
\address{Institute of Systems Science, National University of Singapore, Singapore 119615}

\begin{document}
%\ninept
%
\maketitle
%

\begin{abstract}

The abstract should consist of 1 paragraph describing the motivation for your report and a high-level explanation of the methodology you used and results obtained. Note: this project report template is modified from Stanford University CS230 report template https://cs230.stanford.edu/

\end{abstract}
%

\begin{keywords}
One, two, three, four,
\end{keywords}
%
\section{Introduction}
\label{sec:intro}

Explain the problem and why it is important. Discuss your motivation for pursuing this
problem. Give some background if necessary. Clearly state what the input and output
is. Be very explicit: “The input to our algorithm is an {image, video, RGB-D, audio}. We then use a {neural network, etc.} to output a predicted {age, facial expression, action music genre, etc.}.”

This is very important since different teams have different inputs/outputs spanning different
application domains. Being explicit about this makes it easier for readers.


\section{Literature review}
You should find existing references (e.g., papers, survey, industrial products), group them into categories based on their approaches, and discuss their strengths and weaknesses, as well as how they are similar to and differ from your work. In your opinion, which approaches were clever/good? What is the state-of-the-art?

\section{Dataset}
Describe your dataset: how many training/validation/test examples do you have? Is there
any pre-processing you did? What about normalization or data augmentation? What is the
resolution of your images? Include a citation on where you obtained your dataset from. Try to include examples of your data in the report (e.g. include an image, show a waveform, etc.).



\section{Proposed system}
Describe your proposed system. You might want to use a system architecture or flow chart to illustrate your proposed system. For each module, give a detailed description 
of how it works. Even you use pre-trained model in some modules, provide a description.

\section{Experimental results}

You should also give details about what (hyper)parameters you chose and how
you chose them. What your primary metrics are: accuracy, precision, etc. Provide equations for the metrics if necessary. You also need to evaluate your approach in various experimental setups. For results, you want to have a mixture of tables and plots. To reiterate, you must have both quantitative and qualitative results! Include visualizations of results, examples of where your approach failed and a discussion of why certain approach failed or succeeded. 


Find the result in Figure \ref{figure1}
\begin{figure}[tbh]
    \centerline{\begin{tabular}{cc}
        \includegraphics[width=8cm]{resnet_V2_101.png}\\
    \end{tabular}}
    \caption{deeplabV3 on cityscapes dataset \label{figure1}}
\end{figure}

\subsection{Approach 1: Unet segmentation with MobileNetV2}
Inference speed is big concern due to low computation power, so MobileNetV2 is chosen and input images are resized to 256*256

Find the (hyper)parameters in table \ref{table2}
\begin{table}[tbh]
\caption{The (hyper)parameters}\label{table2} \centerline{
    \begin{tabular}{clc}
    \hline\hline
    train epochs & 36 \\\hline
    batch size & 8 \\\hline
    decay & 1e-4 \\\hline
    \end{tabular}
    }
\end{table}

Dice coefficient works well on imbalanced data, so used as loss function in Equation \ref{equation 1}
\begin{equation}\label{equation 1}
Dice Loss=1-\frac{2\sum_{pixels}(y_{true}*y_{pred})}{\sum_{pixels}(y_{true})+\sum_{pixels}(y_{pred})}
\end{equation}

Find the result in Figure \ref{figure2}
\begin{figure}[tbh]
    \centerline{\begin{tabular}{cc}
        \includegraphics[width=4cm]{unet_grayscale_train_test.png}
        &\includegraphics[width=4cm]{unet_grayscale.JPG}\\
    (a) & (b)
    \end{tabular}}
    \caption{Unet segmentation with MobileNetV2 \label{figure2}}
\end{figure}

Find the performance comparison in Table \ref{table3}
\begin{table}[tbh]
\caption{The performance comparison.}\label{table3} \centerline{
    \begin{tabular}{clc}
    \hline\hline
    Approach & Dice coefficient\\
    Unet segmentation (Approach 1) & $0.7871$ \\\hline
    \end{tabular}
    }
\end{table}

\subsection{Approach 2: Unet segmentation with Patch Pre-processing}
we have small dataset with large image size 3100*3100 and it is measure region by region as well, so created path with size 200*200 , the training size is increased to 73152 from 508, so increased the batch size and reduced the epoch to speed up. we should train more, although the dice coeffient value increased but when look at some sample out, it is sparse 

Find the (hyper)parameters in table \ref{table4}
\begin{table}[tbh]
\caption{The (hyper)parameters}\label{table4} \centerline{
    \begin{tabular}{clc}
    \hline\hline
    train epochs & 16 \\\hline
    batch size & 32 \\\hline
    decay & 1e-4 \\\hline
    \end{tabular}
    }
\end{table}
Dice coefficient is used as loss function and is provided in Equation \eqref{equation 1}
Find the result in Figure \ref{figure3}
\begin{figure}[tbh]
    \centerline{\begin{tabular}{cc}
        \includegraphics[width=4cm]{unet_patch_train_test.JPG}
        &\includegraphics[width=4cm]{unet_patch.png}\\
    (a) & (b)
    \end{tabular}}
    \caption{Unet patch \label{figure3}}
\end{figure}
Find the performance comparison in table \ref{table5}
\begin{table}[tbh]
\caption{The performance comparison.}\label{table5} \centerline{
    \begin{tabular}{clc}
    \hline\hline
    Approach & Dice coefficient\\
    Unet segmentation (Approach 1) & $0.7871$ \\\hline
    Unet patch (Approach 2) & $0.8281$ \\\hline
    \end{tabular}
    }
\end{table}

\subsection{Approach 3: Unet segmentation by Increasing Epoch}
\begin{table}[tbh]
\caption{The (hyper)parameters}\label{table7} \centerline{
    \begin{tabular}{clc}
    \hline\hline
    train epochs & 100 \\\hline
    batch size & 8 \\\hline
    decay & 1e-4 \\\hline
    \end{tabular}
    }
\end{table}
Dice coefficient is used as loss function and is provided in Equation \eqref{equation 1}
\begin{figure}[tbh]
    \centerline{\begin{tabular}{cc}
        \includegraphics[width=4cm]{unet_increase_epoch_train_test.JPG}
        &\includegraphics[width=4cm]{unet_increase_epoch.JPG}\\
    (a) & (b)
    \end{tabular}}
    \caption{Unet with increased epoch \label{figure5}}
\end{figure}

The performance comparison 
\begin{table}[tbh]
\caption{The performance comparison.}\label{table8} \centerline{
    \begin{tabular}{clc}
    \hline\hline
    Approach & Dice coefficient\\
    Unet segmentation (Approach 1) & $0.7871$ \\\hline
    Unet patch (Approach 2) & $0.8281$ \\\hline
    Unet increased epoch (Approach 3) & $0.7858$ \\\hline
    \end{tabular}
    }
\end{table}

\subsection{Approach 4: Unet segmentation with HSV augmentation}
1 HSV augmented image is generated from each original image, trained on top of pre-trained unet model in Approach 1 and HSV augmentation function is provided below , subscript i represents hue or saturation channel, \alpha is drawn from a uniform distribution [-1,1] \ref{equation 4}

\begin{equation}\label{equation 4}
S'_{i}=\alpha_{i}S_{i} 
\end{equation}
\begin{table}[tbh]
\caption{The (hyper)parameters}\label{table9} \centerline{
    \begin{tabular}{clc}
    \hline\hline
    train epochs & 36 \\\hline
    batch size & 8 \\\hline
    decay & 1e-4 \\\hline
    \end{tabular}
    }
\end{table}
Dice coefficient is used as loss function and is provided in Equation \eqref{equation 1}
\begin{figure}[tbh]
    \centerline{\begin{tabular}{cc}
        \includegraphics[width=4cm]{unet_hsv_train_test.JPG}
        &\includegraphics[width=4cm]{unet_hsv.JPG}\\
    (a) & (b)
    \end{tabular}}
    \caption{Unet hsv \label{figure6}}
\end{figure}

\begin{table}[tbh]
\caption{The performance comparison.}\label{table10} \centerline{
    \begin{tabular}{clc}
    \hline\hline
    Approach & Dice coefficient\\
    Unet segmentation (Approach 1) & $0.7871$ \\\hline
    Unet patch (Approach 2) & $0.8281$ \\\hline
    Unet increased epoch (Approach 3) & $0.7858$ \\\hline
    Unet hsv (Approach 4) & $0.8247$ \\\hline
    \end{tabular}
    }
\end{table}

\subsection{Approach 5: Unet segmentation with HED augmentation}
3 HED augmented images are generated from each original image, the training size is increased to 1289 from 508 and HED augmentation function is provided below in Equation \ref{equation 5} , subscript i represents each stain channel, \alpha is drawn from a uniform distribution U(1 − \alpha; 1 + \alpha), \beta is drawn
from a uniform distribution U(−\alpha; \alpha), and typically \alpha = 0.05 

\begin{equation}\label{equation 5}
S'_{i}=\alpha_{i}S_{i}+\beta_{i} 
\end{equation}
\begin{table}[tbh]
\caption{The (hyper)parameters}\label{table11} \centerline{
    \begin{tabular}{clc}
    \hline\hline
    train epochs & 36 \\\hline
    batch size & 8 \\\hline
    decay & 1e-4 \\\hline
    \end{tabular}
    }
\end{table}
Dice coefficient is used as loss function and is provided in Equation \eqref{equation 1} 

\begin{figure}[tbh]
    \centerline{\begin{tabular}{cc}
        \includegraphics[width=4cm]{unet_hed_train_test.JPG}
        &\includegraphics[width=4cm]{unet_hed.JPG}\\
    (a) & (b)
    \end{tabular}}
    \caption{Unet hed \label{figure7}}
\end{figure}

\begin{table}[tbh]
\caption{The performance comparison.}\label{table12} \centerline{
    \begin{tabular}{clc}
    \hline\hline
    Approach & Dice coefficient\\
    Unet segmentation (Approach 1) & $0.7871$ \\\hline
    Unet patch (Approach 2) & $0.8281$ \\\hline
    Unet increased epoch (Approach 3) & $0.7858$ \\\hline
    Unet hsv (Approach 4) & $0.8247$ \\\hline
    Unet hed (Approach 5) & $0.8398$ \\\hline
    \end{tabular}
    }
\end{table}

\subsection{Approach 6: Unet multi-class segmentation }
try Multidimensional Dice coefficient since we have RGB masks 

\begin{table}[tbh]
\caption{The (hyper)parameters}\label{table11} \centerline{
    \begin{tabular}{clc}
    \hline\hline
    train epochs & 36 \\\hline
    batch size & 8 \\\hline
    decay & 1e-4 \\\hline
    \end{tabular}
    }
\end{table}
Multidimensional Dice coefficient is used as loss function and is provided in Figure \ref{figure7} 
\begin{figure}[tbh]
    \centerline{\begin{tabular}{c}
        \includegraphics[width=8cm]{multidimensional-dice.JPG}
    \end{tabular}}
    \caption{Unet multi-class segmentation \label{figure7}}
\end{figure}

\begin{figure}[tbh]
    \centerline{\begin{tabular}{cc}
        \includegraphics[width=4cm]{unet_color_train_test.JPG}
        &\includegraphics[width=4cm]{unet_color.JPG}\\
    (a) & (b)
    \end{tabular}}
    \caption{Unet multi-class segmentation \label{figure8}}
\end{figure}

\begin{table}[tbh]
\caption{The performance comparison.}\label{table12} \centerline{
    \begin{tabular}{clc}
    \hline\hline
    Approach & Dice coefficient\\
    Unet segmentation (Approach 1) & $0.7871$ \\\hline
    Unet patch (Approach 2) & $0.8281$ \\\hline
    Unet increased epoch (Approach 3) & $0.7858$ \\\hline
    Unet hsv (Approach 4) & $0.8247$ \\\hline
    Unet hed (Approach 5) & $0.8398$ \\\hline
    Unet multi-class segmentation (Approach 6) & $0.5514$ \\\hline
    \end{tabular}
    }
\end{table}

\subsection{Approach 7: Unet multi-class HSV }
try multi-class segmentation with HSV augmented data on top of pre-trained multi-class segmentation in Approach 6.

\begin{table}[tbh]
\caption{The (hyper)parameters}\label{table13} \centerline{
    \begin{tabular}{clc}
    \hline\hline
    train epochs & 36 \\\hline
    batch size & 8 \\\hline
    decay & 1e-4 \\\hline
    \end{tabular}
    }
\end{table}
Multidimensional Dice coefficient is used as loss function and is provided in Figure \ref{figure7} 

\begin{figure}[tbh]
    \centerline{\begin{tabular}{cc}
        \includegraphics[width=4cm]{unet_color_hsv_train_test.JPG}
        &\includegraphics[width=4cm]{unet_color_hsv.JPG}\\
    (a) & (b)
    \end{tabular}}
    \caption{Unet multi-class hsv \label{figure9}}
\end{figure}

\begin{table}[tbh]
\caption{The performance comparison.}\label{table14} \centerline{
    \begin{tabular}{clc}
    \hline\hline
    Approach & Dice coefficient\\
    Unet segmentation (Approach 1) & $0.7871$ \\\hline
    Unet patch (Approach 2) & $0.8281$ \\\hline
    Unet increased epoch (Approach 3) & $0.7858$ \\\hline
    Unet hsv (Approach 4) & $0.8247$ \\\hline
    Unet hed (Approach 5) & $0.8398$ \\\hline
    Unet multi-class segmentation (Approach 6) & $0.5514$ \\\hline
    Unet multi-class HSV (Approach 7) & $0.7146$ \\\hline
    \end{tabular}
    }
\end{table}

\subsection{Approach 8: Unet multi-class HED }
try multi-class segmentation with HED augmented data

\begin{table}[tbh]
\caption{The (hyper)parameters}\label{table15} \centerline{
    \begin{tabular}{clc}
    \hline\hline
    train epochs & 36 \\\hline
    batch size & 8 \\\hline
    decay & 1e-4 \\\hline
    \end{tabular}
    }
\end{table}
Multidimensional Dice coefficient is used as loss function and is provided in Figure \ref{figure7} 

\begin{figure}[tbh]
    \centerline{\begin{tabular}{cc}
        \includegraphics[width=4cm]{unet_color_hed_train_test.JPG}
        &\includegraphics[width=4cm]{unet_color_hed.JPG}\\
    (a) & (b)
    \end{tabular}}
    \caption{Unet multi-class hsv \label{figure10}}
\end{figure}

\begin{table}[tbh]
\caption{The performance comparison.}\label{table16} \centerline{
    \begin{tabular}{clc}
    \hline\hline
    Approach & Dice coefficient\\
    Unet segmentation (Approach 1) & $0.7871$ \\\hline
    Unet patch (Approach 2) & $0.8281$ \\\hline
    Unet increased epoch (Approach 3) & $0.7858$ \\\hline
    Unet hsv (Approach 4) & $0.8247$ \\\hline
    Unet hed (Approach 5) & $0.8398$ \\\hline
    Unet multi-class segmentation (Approach 6) & $0.5514$ \\\hline
    Unet multi-class HSV (Approach 7) & $0.7146$ \\\hline
    Unet multi-class HED (Approach 8) & $0.7978$ \\\hline
    \end{tabular}
    }
\end{table}

\subsection{reference}
dataset : https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OCYCMP
Epithelium segmentation using deep learning in H&E-stained prostate specimens with immunohistochemistry as reference standard: https://www.nature.com/articles/s41598-018-37257-4
Otsu’s Thresholding with OpenCV: https://learnopencv.com/otsu-thresholding-with-opencv/
Quantifying the effects of data augmentation and stain color normalization in convolutional neural networks for computational pathology: https://arxiv.org/pdf/1902.06543.pdf
Whole-Slide Mitosis Detection in H&E Breast Histology Using PHH3 as a Reference to Train Distilled Stain-Invariant Convolutional Networks: https://www.researchgate.net/publication/324073594_Whole-Slide_Mitosis_Detection_in_HE_Breast_Histology_Using_PHH3_as_a_Reference_to_Train_Distilled_Stain-Invariant_Convolutional_Networks
Spectral Analysis of CNN for Tomato Disease Identification: https://www.researchgate.net/publication/318134312_Spectral_Analysis_of_CNN_for_Tomato_Disease_Identification
A review of artifacts in histopathology: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6097380/
A Machine Learning Engineer’s Tutorial to Transfer Learning for Multi-class Image Segmentation Using U-net : https://towardsdatascience.com/a-machine-learning-engineers-tutorial-to-transfer-learning-for-multi-class-image-segmentation-b34818caec6b 
Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation: https://arxiv.org/pdf/1802.02611v3.pdf
DeepLab-v3-plus Semantic Segmentation in TensorFlow: https://github.com/rishizek/tensorflow-deeplab-v3-plus
Xception: Implementing from scratch using Tensorflow: https://towardsdatascience.com/xception-from-scratch-using-tensorflow-even-better-than-inception-940fb231ced9
UNET Segmentation with Pretrained MobileNetV2 as Encoder: https://idiotdeveloper.com/unet-segmentation-with-pretrained-mobilenetv2-as-encoder/

\section{Conclusions and future work}
Summarize your report and reiterate key points. Why do you think that some algorithms worked better than others? For future work, if you had more time, more team members, or more computational resources, what would you explore?

\section{Contributions}
This section should describe contributions of each team member to the project.

\bibliographystyle{IEEEbib}
\bibliography{references}

\end{document}
